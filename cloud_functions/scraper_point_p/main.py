import functions_framework
from supabase import create_client, Client
import os
import requests
from bs4 import BeautifulSoup

# Initialize Supabase client
url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(url, key)

@functions_framework.cloud_event
def scrape_point_p(cloud_event):
    try:
        # Example URL for a category on Point P
        # In a real scenario, you would have a list of categories to scrape
        scrape_url = "https://www.pointp.fr/c/gros-oeuvre/plancher-hourdis-poutrelles-entrevous/p/10102"

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
        }
        response = requests.get(scrape_url, headers=headers)
        response.raise_for_status() # Raise an exception for bad status codes

        soup = BeautifulSoup(response.content, 'html.parser')

        # This is a placeholder selector. The actual selector would need to be determined by inspecting the Point P website.
        products = soup.select('.product-item') 

        for product in products:
            # This is a placeholder for the actual data extraction logic
            name = product.select_one('.product-title').text.strip()
            price_str = product.select_one('.product-price').text.strip().replace('â‚¬', '').replace(',', '.').strip()
            price = float(price_str)
            reference = product.select_one('.product-reference').text.strip()

            # Upsert product into Supabase
            supabase.table('products').upsert({
                'name': name,
                'selling_price_ht': price,
                'reference': reference,
                'source': 'pointp',
                # You would need to generate a user_id if you want to associate these products with a user
                # 'user_id': 'some-user-id' 
            }).execute()

        print(f"Successfully scraped {len(products)} products from Point P.")
        return {'success': True}, 200

    except Exception as e:
        print(f"Error scraping Point P: {e}")
        return {'success': False, 'error': str(e)}, 500
